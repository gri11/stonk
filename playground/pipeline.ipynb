{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OefjyxueoGsK"
      },
      "source": [
        "# Stonk\n",
        "We aim to forcast stock price value by using LSTM with Pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roINhp6eoGsL"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_stock_data(ticker, start, end):\n",
        "    stock_data = yf.Ticker(ticker).history(start=start, end=end)\n",
        "    return stock_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "snp_hist = get_stock_data('^GSPC', start=\"2004-08-19\", end=\"2019-10-05\")\n",
        "\n",
        "snp_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = snp_hist[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "eKO5UE4BD7g7",
        "outputId": "a408db8f-2f32-463d-b66e-c020f53a2914"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "plot_template = dict(\n",
        "    layout=go.Layout({\n",
        "        \"font_size\": 18,\n",
        "        \"xaxis_title_font_size\": 24,\n",
        "        \"yaxis_title_font_size\": 24})\n",
        ")\n",
        "\n",
        "fig = px.line(df['Open'], labels=dict(\n",
        "    created_at=\"Date\", value=\"Open\", variable=\"Sensor\"\n",
        "))\n",
        "fig.update_layout(\n",
        "  template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz0kYc8uoGsh"
      },
      "source": [
        "## Create the target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shift_lead(df, target, target_col, forecast_lead):\n",
        "    df[target_col] = df[target].shift(-forecast_lead)\n",
        "    df = df.iloc[:-forecast_lead]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uELZWZVHoGsh"
      },
      "outputs": [],
      "source": [
        "target = \"Open\"\n",
        "features = list(df.columns.difference([target]))\n",
        "\n",
        "forecast_lead = 1\n",
        "target_col = f\"{target}_lead{forecast_lead}\"\n",
        "\n",
        "df = shift_lead(df, target, target_col, forecast_lead)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"features: {features}, target_col: {target_col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCfYZ_lGoGsi"
      },
      "source": [
        "## Create a hold-out test set and preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBXPBOqroGsi",
        "outputId": "89fdd433-a653-431e-ff0b-8c5a4b92fcca"
      },
      "outputs": [],
      "source": [
        "test_start = \"2019-01-01\"\n",
        "val_start = \"2018-01-01\"\n",
        "\n",
        "df_train = df.loc[:val_start].copy()\n",
        "df_val = df.loc[val_start:test_start].copy()\n",
        "df_test = df.loc[test_start:].copy()\n",
        "\n",
        "print(\"Test set fraction:\", len(df_test) / len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5646NJnGoGsi"
      },
      "source": [
        "## Standardize the features and target, based on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTVap0kkoGsi"
      },
      "outputs": [],
      "source": [
        "target_mean = df_train[target].mean()\n",
        "target_stdev = df_train[target].std()\n",
        "\n",
        "for c in df_train.columns:\n",
        "    mean = df_train[c].mean()\n",
        "    stdev = df_train[c].std()\n",
        "\n",
        "    df_train[c] = (df_train[c] - mean) / stdev\n",
        "    df_val[c] = (df_val[c] - mean) / stdev\n",
        "    df_test[c] = (df_test[c] - mean) / stdev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SjVLo7FoGsi"
      },
      "source": [
        "## Create datasets that PyTorch `DataLoader` can work with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B_x4fHZoGsj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, dataframe, target, features, sequence_length=5):\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.sequence_length = sequence_length\n",
        "        self.y = torch.tensor(dataframe[self.target].values).float()\n",
        "        self.X = torch.tensor(dataframe[self.features].values).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        if i >= self.sequence_length - 1:\n",
        "            i_start = i - self.sequence_length + 1\n",
        "            x = self.X[i_start:(i + 1), :]\n",
        "        else:\n",
        "            padding = self.X[0].repeat(self.sequence_length - i - 1, 1)\n",
        "            x = self.X[0:(i + 1), :]\n",
        "            x = torch.cat((padding, x), 0)\n",
        "\n",
        "        return x, self.y[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu5I547IoGsj",
        "outputId": "a6abcc0e-f0de-415a-b4d9-a4e42350c4d5"
      },
      "outputs": [],
      "source": [
        "i = 27\n",
        "sequence_length = 4\n",
        "\n",
        "train_dataset = SequenceDataset(\n",
        "    df_train,\n",
        "    target=target,\n",
        "    features=features,\n",
        "    sequence_length=sequence_length\n",
        ")\n",
        "\n",
        "X, y = train_dataset[i]\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRBl-HIGoGsk",
        "outputId": "498171bd-52f7-4685-f16d-2ac107423511"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "torch.manual_seed(99)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
        "\n",
        "X, y = next(iter(train_loader))\n",
        "print(X.shape)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzQKgf5RoGsk"
      },
      "source": [
        "## Create the datasets and data loaders for real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi0vsoH1oGsk"
      },
      "source": [
        "In this tutorial we will\n",
        "use sequences of length 60 (60 days) to forcast 1 day ahead.\n",
        "\n",
        "The PyTorch `DataLoader` is a very convenient way to iterate through these datasets. For\n",
        "the training set we'll shuffle (the rows *within* each training sequence are not\n",
        "shuffled, only the order in which we draw those blocks). For the test set, shuffling\n",
        "isn't necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IpeaDGKoGsl",
        "outputId": "f292d756-2508-4572-c872-13d60e382a2a"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(101)\n",
        "\n",
        "batch_size = 32\n",
        "sequence_length = 60\n",
        "\n",
        "train_dataset = SequenceDataset(\n",
        "    df_train,\n",
        "    target=target,\n",
        "    features=features,\n",
        "    sequence_length=sequence_length\n",
        ")\n",
        "val_dataset = SequenceDataset(\n",
        "    df_val,\n",
        "    target=target,\n",
        "    features=features,\n",
        "    sequence_length=sequence_length\n",
        ")\n",
        "test_dataset = SequenceDataset(\n",
        "    df_test,\n",
        "    target=target,\n",
        "    features=features,\n",
        "    sequence_length=sequence_length\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "X, y = next(iter(train_loader))\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def MAPE(Y_actual,Y_Predicted):\n",
        "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
        "    return mape\n",
        "\n",
        "def MASE(pred, y):\n",
        "    pred = torch.tensor(pred)\n",
        "    y = torch.tensor(y)\n",
        "    return float(torch.mean(torch.abs(pred - y) / torch.mean(torch.abs(y[1:] - y[:-1]))))\n",
        "\n",
        "def SMAPE(pred, y):\n",
        "    pred = torch.tensor(pred)\n",
        "    y = torch.tensor(y)\n",
        "    return float(200 * torch.mean(torch.abs(pred - y) / (torch.abs(y) + torch.abs(pred))))\n",
        "\n",
        "def MAE(pred, y):\n",
        "    pred = torch.tensor(pred)\n",
        "    y = torch.tensor(y)\n",
        "    return float(torch.mean(torch.abs(pred - y)))\n",
        "\n",
        "def sharp_ratio(pred, y):\n",
        "    pred = torch.tensor(pred)\n",
        "    y = torch.tensor(y)\n",
        "    return float(torch.mean((pred - y) / torch.std(y)))\n",
        "\n",
        "def directional_accuracy(Y_actual, Y_predicted):\n",
        "    \"\"\"\n",
        "    Calculate the directional accuracy of predictions.\n",
        "\n",
        "    Parameters:\n",
        "        Y_actual (array-like): Array of actual stock prices.\n",
        "        Y_predicted (array-like): Array of predicted stock prices.\n",
        "\n",
        "    Returns:\n",
        "        float: Directional accuracy percentage.\n",
        "    \"\"\"\n",
        "    actual_changes = np.sign(np.diff(Y_actual))\n",
        "    predicted_changes = np.sign(np.diff(Y_predicted))\n",
        "    correct_predictions = np.sum(actual_changes == predicted_changes)\n",
        "    total_predictions = len(actual_changes)\n",
        "    directional_accuracy = correct_predictions / total_predictions * 100\n",
        "    return directional_accuracy\n",
        "\n",
        "def evaluate(y_true, y_pred, save=False, model_name=\"model_name\"):\n",
        "    performance = {}\n",
        "    performance['MAPE'] = MAPE(y_true, y_pred)\n",
        "    performance['MASE'] = MASE(y_true, y_pred)\n",
        "    performance['RMSE'] = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    performance['SMAPE'] = SMAPE(y_true, y_pred)\n",
        "    performance['MAE'] = MAE(y_true, y_pred)\n",
        "    performance['sharp_ratio'] = sharp_ratio(y_true, y_pred)\n",
        "    performance['Directional Accuracy'] = directional_accuracy(y_true, y_pred)\n",
        "\n",
        "    if save:\n",
        "        pd.DataFrame(performance, index=[model_name]).to_csv(f'../performance/{model_name}.csv')\n",
        "        \n",
        "    return performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w__P7b2vL2-S"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9qjwSZGoGsl"
      },
      "source": [
        "## The model and learning algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAI32yVsrGog"
      },
      "source": [
        "![picture](https://i.stack.imgur.com/SjnTl.png)\n",
        "\n",
        "Credit : https://stackoverflow.com/questions/48302810/whats-the-difference-between-hidden-and-output-in-pytorch-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB-LjIMXYuG3"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEm8dn6yoGsl"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class ShallowRegressionLSTM(nn.Module):\n",
        "    def __init__(self, num_features, hidden_units):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features  # this is the number of features\n",
        "        self.hidden_units = hidden_units\n",
        "        self.num_layers = 4\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=num_features,\n",
        "            hidden_size=hidden_units,\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        # print(\"batch_size :\",batch_size)\n",
        "        # initialize the hidden and cell state of the LSTM layer\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).to(device).requires_grad_()\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).to(device).requires_grad_()\n",
        "\n",
        "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
        "        out = self.linear(hn[-1]).flatten()  # get the output of the last hidden layer\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsAE3hw4oGsn"
      },
      "outputs": [],
      "source": [
        "learning_rate = 5e-4\n",
        "num_hidden_units = 60\n",
        "\n",
        "model = ShallowRegressionLSTM(num_features=len(features), hidden_units=num_hidden_units)\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiRYwqeOTWTZ",
        "outputId": "c4febf0e-91c1-430c-d4a7-1ab740a7b75c"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(32, 60, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWoZlk43oGsn"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dogVellgMdH"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EVJhpSnoGso"
      },
      "outputs": [],
      "source": [
        "def train_model(data_loader, model, loss_function, optimizer):\n",
        "    num_batches = len(data_loader)\n",
        "    # print( num_batches )\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for X, y in data_loader:\n",
        "        # print(X.shape, y.shape)\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        output = model(X)\n",
        "        loss = loss_function(output, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\"Train loss: {avg_loss}\")\n",
        "\n",
        "def test_model(data_loader, model, loss_function, best_val_loss):\n",
        "\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(X)\n",
        "            total_loss += loss_function(output, y).item()\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\"Test loss: {avg_loss}\")\n",
        "    if avg_loss < best_val_loss:\n",
        "        best_val_loss = avg_loss\n",
        "        torch.save(model.state_dict(), '../model/lstm.pth')\n",
        "        print('Save new best model')\n",
        "    return best_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "92463d63210c45dd9331767c8b3188f2",
            "12ba59388b344b009e9ff1a130672b40",
            "19ae245c3a1e4269bcc74917dcf62285",
            "6015fb50d0624ca8a4cc0c49e45a7732",
            "ca40abd7b34e4197b522ce8b471be95b",
            "68ccdf5616514a5091dadfc0ef31a59c",
            "34f8d1cf490c441ab1c7e7446f14b64f",
            "d780343266a94c1d906535353e39a910",
            "246264fe31d34762b72938555f0d5800",
            "4be36467cce24930839213fbc7af5d7b",
            "aa39bb464ef644cc914b88644cad4aca"
          ]
        },
        "id": "_RwmIPZToGsp",
        "outputId": "477b4447-81dd-4492-86e6-e51dfa344006"
      },
      "outputs": [],
      "source": [
        "best_val_loss = torch.inf\n",
        "for ix_epoch in tqdm(range(100)):\n",
        "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
        "    train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
        "    best_val_loss = test_model(val_loader, model, loss_function, best_val_loss)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6DYsOsuoGsp"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0Y-4tuvoGsp"
      },
      "outputs": [],
      "source": [
        "def predict(data_loader, model):\n",
        "    \"\"\"Just like `test_loop` function but keep track of the outputs instead of the loss\n",
        "    function.\n",
        "    \"\"\"\n",
        "    output = torch.tensor([])\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, _ in data_loader:\n",
        "            X = X.to(device)\n",
        "            y_star = model(X)\n",
        "            output = torch.cat((output, y_star.detach().cpu()), 0)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZn84iyxVaPJ"
      },
      "outputs": [],
      "source": [
        "PATH = '../model/lstm.pth'\n",
        "model.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "541fAaonoGsp"
      },
      "outputs": [],
      "source": [
        "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "ystar_col = \"Model forecast\"\n",
        "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
        "df_val[ystar_col] = predict(val_loader, model).numpy()\n",
        "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
        "\n",
        "df_out = pd.concat((df_train, df_val, df_test))[[target, ystar_col]]\n",
        "\n",
        "for c in df_out.columns:\n",
        "    df_out[c] = df_out[c] * target_stdev + target_mean\n",
        "\n",
        "print(df_out)\n",
        "\n",
        "df_out.to_csv('../prediction/lstm.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzH9PG_attOm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def MAPE(Y_actual,Y_Predicted):\n",
        "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
        "    return mape\n",
        "\n",
        "print( 'MPAE =', MAPE(df_test['Open_lead1'], df_test['Model forecast']) )\n",
        "print( 'RMSE =', math.sqrt(mean_squared_error(df_test['Open_lead1'], df_test['Model forecast'])) )\n",
        "\n",
        "evaluate(df_test['Open_lead1'], df_test['Model forecast'], save=True, model_name=\"lstm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGZQ5iiHoGsq"
      },
      "outputs": [],
      "source": [
        "fig = px.line(df_out, labels={'value': \"Open\", 'created_at': 'Date'})\n",
        "fig.add_vline(x=val_start, line_width=4, line_dash=\"dash\")\n",
        "fig.add_vline(x=test_start, line_width=4, line_dash=\"dash\")\n",
        "# fig.add_annotation(xref=\"paper\", x=0.75, yref=\"paper\", y=0.8, text=\"Test set start\", showarrow=False)\n",
        "fig.update_layout(\n",
        "  template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQwyK33bJFSH"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHAw52RVMGyH"
      },
      "source": [
        "## The model and learning algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMSusByVJTJH"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jweI4U_1JTJH"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class ShallowRegressionGRU(nn.Module):\n",
        "    def __init__(self, num_features, hidden_units):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features  # this is the number of features\n",
        "        self.hidden_units = hidden_units\n",
        "        self.num_layers = 4\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=num_features,\n",
        "            hidden_size=hidden_units,\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # initialize the hidden and cell state of the LSTM layer\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).to(device).requires_grad_()\n",
        "\n",
        "        _, hn = self.gru(x, h0)\n",
        "        out = self.linear(hn[-1]).flatten()  # get the output of the last hidden layer\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viPODmc0JTJI"
      },
      "outputs": [],
      "source": [
        "learning_rate = 5e-4\n",
        "num_hidden_units = 60\n",
        "\n",
        "model = ShallowRegressionGRU(num_features=len(features), hidden_units=num_hidden_units)\n",
        "model.to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glqwFIk4JTJI"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(32, 60, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW7NS5hkJTJJ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF3vVwSpJTJJ"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cl30YYaJTJJ"
      },
      "outputs": [],
      "source": [
        "def train_model(data_loader, model, loss_function, optimizer):\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for X, y in data_loader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        output = model(X)\n",
        "        loss = loss_function(output, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\"Train loss: {avg_loss}\")\n",
        "\n",
        "def test_model(data_loader, model, loss_function, best_val_loss):\n",
        "\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(X)\n",
        "            total_loss += loss_function(output, y).item()\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\"Test loss: {avg_loss}\")\n",
        "    if avg_loss < best_val_loss:\n",
        "        best_val_loss = avg_loss\n",
        "        torch.save(model.state_dict(), '../model/gru.pth')\n",
        "        print('Save new best model')\n",
        "    return best_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1xht__JJTJJ"
      },
      "outputs": [],
      "source": [
        "best_val_loss = torch.inf\n",
        "for ix_epoch in tqdm(range(100)):\n",
        "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
        "    train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
        "    best_val_loss = test_model(val_loader, model, loss_function, best_val_loss)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1wq-damLoto"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGebRAKoLoto"
      },
      "outputs": [],
      "source": [
        "def predict(data_loader, model):\n",
        "    \"\"\"Just like `test_loop` function but keep track of the outputs instead of the loss\n",
        "    function.\n",
        "    \"\"\"\n",
        "    output = torch.tensor([])\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, _ in data_loader:\n",
        "            X = X.to(device)\n",
        "            y_star = model(X)\n",
        "            output = torch.cat((output, y_star.detach().cpu()), 0)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vehEFCADLotp"
      },
      "outputs": [],
      "source": [
        "PATH = './model_gru.pth'\n",
        "model.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd-gdyAYLotp"
      },
      "outputs": [],
      "source": [
        "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "ystar_col = \"Model forecast\"\n",
        "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
        "df_val[ystar_col] = predict(val_loader, model).numpy()\n",
        "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
        "\n",
        "df_out = pd.concat((df_train, df_val, df_test))[[target, ystar_col]]\n",
        "\n",
        "for c in df_out.columns:\n",
        "    df_out[c] = df_out[c] * target_stdev + target_mean\n",
        "\n",
        "print(df_out)\n",
        "\n",
        "df_out.to_csv('../prediction/gru.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ax1iMUtwUBO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def MAPE(Y_actual,Y_Predicted):\n",
        "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
        "    return mape\n",
        "\n",
        "print( 'MPAE =', MAPE(df_test['Open_lead1'], df_test['Model forecast']) )\n",
        "print( 'RMSE =', math.sqrt(mean_squared_error(df_val['Open_lead1'], df_val['Model forecast'])) )\n",
        "\n",
        "evaluate(df_test['Open_lead1'], df_test['Model forecast'], save=True, model_name=\"gru\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hM-41IhLotp"
      },
      "outputs": [],
      "source": [
        "fig = px.line(df_out, labels={'value': \"Open\", 'created_at': 'Date'})\n",
        "fig.add_vline(x=val_start, line_width=4, line_dash=\"dash\")\n",
        "fig.add_vline(x=test_start, line_width=4, line_dash=\"dash\")\n",
        "# fig.add_annotation(xref=\"paper\", x=0.75, yref=\"paper\", y=0.8, text=\"Test set start\", showarrow=False)\n",
        "fig.update_layout(\n",
        "  template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoQ5cv1GD550"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL5mpT6STqq5"
      },
      "source": [
        "# ResNLS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow8Ftta9mnFq"
      },
      "source": [
        "**Data**\n",
        "\n",
        "\n",
        "*   10 consecutive trading days as the unit step\n",
        "*   clean\n",
        "\n",
        "\n",
        "*   normalize it to eliminate scale differences\n",
        "*   transform it into tensors\n",
        "\n",
        "**Train** : closing price data of the SSE Composite\n",
        "Index from January 1, 2011 to December 31, 2020\n",
        "\n",
        "**Test** : closing price data from January 1, 2021 to December 31, 2021\n",
        "\n",
        "\n",
        "\n",
        "**Conv**\n",
        "\n",
        "\n",
        "*   filter = 64\n",
        "*   kernel size = 3\n",
        "\n",
        "*   applies ReLU as the activation\n",
        "function\n",
        "*   weight decay of 1e-5\n",
        "\n",
        "**dropout layer** with a retain probability of 0.8\n",
        "\n",
        "**LSTM**\n",
        "\n",
        "\n",
        "*   hidden size = 32\n",
        "\n",
        "**optimizer** Adam\n",
        "\n",
        "batch size (64) with a larger initial\n",
        "learning rate (1e-3) are preferred\n",
        "\n",
        "epoch = 50\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-bD7GryW3yz"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK96M8AakMV9",
        "outputId": "3a349d74-5c40-4826-b78f-eebc3f84e20e"
      },
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgVqqbX0W1xG",
        "outputId": "10aab45f-b273-452c-cd48-ef86e2d9bcd0"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(101)\n",
        "# aj\n",
        "# batch_size = 32\n",
        "# sequence_length = 60\n",
        "\n",
        "# # best in paper\n",
        "batch_size = 64\n",
        "sequence_length = 5\n",
        "\n",
        "train_dataset = SequenceDataset(\n",
        "    df_train,\n",
        "    target=target,\n",
        "    features=features,\n",
        "    sequence_length=sequence_length\n",
        ")\n",
        "val_dataset = SequenceDataset(\n",
        "    df_val,\n",
        "    target=target,\n",
        "    features=features,\n",
        "    sequence_length=sequence_length\n",
        ")\n",
        "test_dataset = SequenceDataset(\n",
        "    df_test,\n",
        "    target=target,\n",
        "    features=features,\n",
        "    sequence_length=sequence_length\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "X, y = next(iter(train_loader))\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pT7fQMXTyxo"
      },
      "source": [
        "## The model and learning algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zELe_iAST1E2"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMfZq7jgX_gA"
      },
      "outputs": [],
      "source": [
        "# input = (batch,10,4)\n",
        "# output = (batch,10,4)\n",
        "# filter of each conv = 64\n",
        "# conv1 = (10) -> (64)\n",
        "# conv2 = (64) -> (64)\n",
        "# linear = (64) -> (10)\n",
        "# shortcut = (10) -> (10)\n",
        "class ResBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, filter, kernel_size=3, stride=1, padding=1):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(in_channels, filter, kernel_size, stride, padding)\n",
        "        self.conv2 = torch.nn.Conv1d(filter, filter, kernel_size, stride, padding)\n",
        "        self.linear = torch.nn.Linear(filter, out_channels)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.bn1 = torch.nn.BatchNorm1d(filter, eps=1e-5)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(filter, eps=1e-5)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        # intialise weights of the attention mechanism\n",
        "        self.weight = nn.Parameter(torch.zeros(1)).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.bn1(out)\n",
        "\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        out = self.weight*out\n",
        "        out += x.view(x.size(0), -1)\n",
        "        return out\n",
        "\n",
        "# model = ResBlock(10, 10, 64)\n",
        "# summary(model, input_size=(1, 10, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyIF7mgHX5QJ"
      },
      "outputs": [],
      "source": [
        "class ResNLS(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hidden_layer, num_layer, num_feature=4, filter=64, kernel_size=3):\n",
        "        super(ResNLS, self).__init__()\n",
        "        self.resblock1 = ResBlock(in_channels, in_channels, filter)\n",
        "        self.resblock2 = ResBlock(in_channels, in_channels, filter)\n",
        "        self.resblock3 = ResBlock(in_channels, in_channels, filter)\n",
        "        self.resblock4 = ResBlock(in_channels, in_channels, filter)\n",
        "        self.num_layers = num_layer\n",
        "        self.hidden_layer = hidden_layer\n",
        "        self.lstm = torch.nn.LSTM(num_feature, hidden_layer, num_layer, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(hidden_layer, out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        out = torch.split(x, 1, 2)\n",
        "        out1 = self.resblock1(out[0])\n",
        "        out2 = self.resblock2(out[1])\n",
        "        out3 = self.resblock3(out[2])\n",
        "        out4 = self.resblock4(out[3])\n",
        "        out1 = out1.unsqueeze(2)\n",
        "        out2 = out2.unsqueeze(2)\n",
        "        out3 = out3.unsqueeze(2)\n",
        "        out4 = out4.unsqueeze(2)\n",
        "        out = torch.cat((out1, out2, out3, out4), 2)\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_layer).to(device).requires_grad_()\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_layer).to(device).requires_grad_()\n",
        "        _, (hn, _) = self.lstm(out, (h0, c0))\n",
        "        out = self.linear(hn[-1]).flatten()\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6YU9328L-2l",
        "outputId": "a07eb2ec-661a-4b1e-b483-90bc99b8b82a"
      },
      "outputs": [],
      "source": [
        "# Init from paper\n",
        "num_consecutive_days = sequence_length\n",
        "days_pred = 1\n",
        "# num_lstm_hiddensize = 32\n",
        "num_lstm_hiddensize = 64\n",
        "# lstm_layers = 4 # from aj\n",
        "# lstm_layers = 64 # from paper\n",
        "lstm_layers = 1\n",
        "\n",
        "num_features = len(features)\n",
        "filters = 64  # Number of filters in convolutional layers\n",
        "kernel_size = 3  # Kernel size for convolutional layers\n",
        "\n",
        "model = ResNLS(num_consecutive_days,\n",
        "               days_pred,\n",
        "               num_lstm_hiddensize,\n",
        "               lstm_layers,\n",
        "               num_features,\n",
        "               filters,\n",
        "               kernel_size)\n",
        "model.to(device)\n",
        "summary(model, input_size=(batch_size, num_consecutive_days, num_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDae-VTbjRmD"
      },
      "outputs": [],
      "source": [
        "parameters_to_decay = []\n",
        "for name, param in model.named_parameters():\n",
        "  if 'conv1' in name or 'conv2' in name:\n",
        "        parameters_to_decay.append(param)\n",
        "\n",
        "weight_decay=1e-5\n",
        "learning_rate = 1e-3 # Optimizer lr\n",
        "# optimizer = torch.optim.Adam([{'params': parameters_to_decay, 'weight_decay': weight_decay}], lr=learning_rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "\n",
        "loss_function = nn.MSELoss() # We use Mean Absolute Error (MAE), Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi3Qe9PGGzCx"
      },
      "outputs": [],
      "source": [
        "# class RealResNLS(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(ResNLS, self).__init__()\n",
        "\n",
        "#         # intialise weights of the attention mechanism\n",
        "#         self.weight = nn.Parameter(torch.zeros(1)).to(device)\n",
        "\n",
        "#         # intialise cnn structure\n",
        "#         self.cnn = nn.Sequential(\n",
        "#             nn.Conv1d(in_channels=1, out_channels=n_hidden, kernel_size=3, stride=1, padding=1), # ((5 + 1*2 - 3)/1 + 1) = 5\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.BatchNorm1d(n_hidden, eps=1e-5),\n",
        "#             nn.Dropout(0.1),\n",
        "\n",
        "#             nn.Conv1d(in_channels=n_hidden, out_channels=n_hidden, kernel_size=3, stride=1, padding=1), # ((5 + 1*2 - 3)/1 + 1) = 5\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.BatchNorm1d(n_hidden, eps=1e-5),\n",
        "\n",
        "#             nn.Flatten(),\n",
        "#             nn.Linear(n_input * n_hidden, n_input)\n",
        "#         )\n",
        "\n",
        "#         # intialise lstm structure\n",
        "#         self.lstm = nn.LSTM(n_input, n_hidden, batch_first=True, bidirectional=False)\n",
        "#         self.linear = nn.Linear(n_hidden, 1)\n",
        "\n",
        "\n",
        "#     def forward(self, x):\n",
        "\n",
        "#         cnn_output = self.cnn(x)\n",
        "#         cnn_output = cnn_output.view(-1, 1, n_input)\n",
        "\n",
        "#         residuals = x + self.weight * cnn_output\n",
        "\n",
        "#         _, (h_n, _)  = self.lstm(residuals)\n",
        "#         y_hat = self.linear(h_n[0,:,:])\n",
        "\n",
        "#         return y_hat\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxM_F25cTzpY"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkdL-txKkTZu"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train_model(data_loader, model, loss_function, optimizer):\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for X, y in data_loader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        output = model(X)\n",
        "        loss = loss_function(output, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\"Train loss: {avg_loss}\")\n",
        "\n",
        "def test_model(data_loader, model, loss_function, best_val_loss):\n",
        "\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(X)\n",
        "            total_loss += loss_function(output, y).item()\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\"Test loss: {avg_loss}\")\n",
        "    if avg_loss < best_val_loss:\n",
        "        best_val_loss = avg_loss\n",
        "        torch.save(model.state_dict(), 'model.pth')\n",
        "        print('Save new best model')\n",
        "    return best_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "367cef23640a4da9a1af04b9fbaa8a27",
            "dcb723c3f917474c8af64be7c5f92517",
            "e5c520643bff4e8d88107a9e09e2f832",
            "0dc977552c4444ee871c590b208d7cfb",
            "4df3be4f7911417497bd051d23b4c613",
            "def03ac052304dfb8a4c34082fd4c0f6",
            "6d0c69dd65c24fd4a5a5898e75d5d64a",
            "c0eefb3b3952463d8f4347c4639a06d9",
            "2d6f7f662e8a4e3bb073e958ffa97269",
            "057dd4f81caa4b10b86af42fc6898b6d",
            "c0e4307aa3b343d9ac4077e0e0b8cd64"
          ]
        },
        "id": "poLB0qHmkkeV",
        "outputId": "9e0f5343-643c-404c-b976-9d5d525246c0"
      },
      "outputs": [],
      "source": [
        "best_val_loss = torch.inf\n",
        "for ix_epoch in tqdm(range(100)):\n",
        "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
        "    train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
        "    best_val_loss = test_model(val_loader, model, loss_function, best_val_loss)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxZc8Na_T1VW"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rg-a1VlgTtLW"
      },
      "outputs": [],
      "source": [
        "def predict(data_loader, model):\n",
        "    \"\"\"Just like `test_loop` function but keep track of the outputs instead of the loss\n",
        "    function.\n",
        "    \"\"\"\n",
        "    output = torch.tensor([])\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, _ in data_loader:\n",
        "            X = X.to(device)\n",
        "            y_star = model(X)\n",
        "            output = torch.cat((output, y_star.detach().cpu()), 0)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so7CoJ1yl_Vj"
      },
      "outputs": [],
      "source": [
        "# PATH = './model_gru.pth'\n",
        "# model.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X1cKl1nmBe6",
        "outputId": "22859c28-6cbd-440f-aadd-986178c59beb"
      },
      "outputs": [],
      "source": [
        "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "ystar_col = \"Model forecast\"\n",
        "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
        "df_val[ystar_col] = predict(val_loader, model).numpy()\n",
        "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
        "\n",
        "df_out = pd.concat((df_train, df_val, df_test))[[target, ystar_col]]\n",
        "\n",
        "for c in df_out.columns:\n",
        "    df_out[c] = df_out[c] * target_stdev + target_mean\n",
        "\n",
        "print(df_out)\n",
        "\n",
        "df_out.to_csv('../prediction/resnls.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdXmJDB_ZSlQ",
        "outputId": "9eaf468b-784f-4069-aa8c-56130e066320"
      },
      "outputs": [],
      "source": [
        "def MASE(pred, y):\n",
        "    pred = torch.tensor(pred)\n",
        "    y = torch.tensor(y)\n",
        "    return float(torch.mean(torch.abs(pred - y) / torch.mean(torch.abs(y[1:] - y[:-1]))))\n",
        "\n",
        "def SMAPE(pred, y):\n",
        "    pred = torch.tensor(pred)\n",
        "    y = torch.tensor(y)\n",
        "    return float(200 * torch.mean(torch.abs(pred - y) / (torch.abs(y) + torch.abs(pred))))\n",
        "\n",
        "def MAE(pred, y):\n",
        "    pred = torch.tensor(pred)\n",
        "    y = torch.tensor(y)\n",
        "    return float(torch.mean(torch.abs(pred - y)))\n",
        "\n",
        "def sharp_ratio(pred, y):\n",
        "    pred = torch.tensor(pred)\n",
        "    y = torch.tensor(y)\n",
        "    return float(torch.mean((pred - y) / torch.std(y)))\n",
        "\n",
        "def directional_accuracy(Y_actual, Y_predicted):\n",
        "    \"\"\"\n",
        "    Calculate the directional accuracy of predictions.\n",
        "\n",
        "    Parameters:\n",
        "        Y_actual (array-like): Array of actual stock prices.\n",
        "        Y_predicted (array-like): Array of predicted stock prices.\n",
        "\n",
        "    Returns:\n",
        "        float: Directional accuracy percentage.\n",
        "    \"\"\"\n",
        "    actual_changes = np.sign(np.diff(Y_actual))\n",
        "    predicted_changes = np.sign(np.diff(Y_predicted))\n",
        "    correct_predictions = np.sum(actual_changes == predicted_changes)\n",
        "    total_predictions = len(actual_changes)\n",
        "    directional_accuracy = correct_predictions / total_predictions * 100\n",
        "    return directional_accuracy\n",
        "\n",
        "def evaluate(y_true, y_pred, save=False, model_name=\"ModelName\"):\n",
        "    performance = {}\n",
        "    performance['MAPE'] = MAPE(y_true, y_pred)\n",
        "    performance['MASE'] = MASE(y_true, y_pred)\n",
        "    performance['RMSE'] = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    performance['SMAPE'] = SMAPE(y_true, y_pred)\n",
        "    performance['MAE'] = MAE(y_true, y_pred)\n",
        "    performance['sharp_ratio'] = sharp_ratio(y_true, y_pred)\n",
        "    performance['Directional Accuracy'] = directional_accuracy(y_true, y_pred)\n",
        "\n",
        "    if save:\n",
        "        pd.DataFrame(performance, index=[model_name]).to_csv(f'../performance/{model_name}.csv')\n",
        "        \n",
        "    return performance\n",
        "\n",
        "print( 'MASE =', MASE(df_test['Open_lead1'], df_test['Model forecast']))\n",
        "print( 'RMSE =', math.sqrt(mean_squared_error(df_test['Open_lead1'], df_test['Model forecast'])) )\n",
        "print( 'SMAPE =', SMAPE(df_test['Open_lead1'], df_test['Model forecast']))\n",
        "print( 'MAE =', MAE(df_test['Open_lead1'], df_test['Model forecast']))\n",
        "print( 'sharp_ratio =', sharp_ratio(df_test['Open_lead1'], df_test['Model forecast']))\n",
        "print('Directional Accuracy =', directional_accuracy(df_test['Open_lead1'], df_test['Model forecast']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "perf = evaluate(df_test['Open_lead1'], df_test['Model forecast'])\n",
        "perf = pd.DataFrame(perf, index=['ResNLS'])\n",
        "display(perf)\n",
        "\n",
        "perf.to_csv('../performance/resnls.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "n_I7xckFmKQm",
        "outputId": "564ea5d9-6977-4838-9a7c-610d09e9b0ae"
      },
      "outputs": [],
      "source": [
        "fig = px.line(df_out, labels={'value': \"Open\", 'created_at': 'Date'})\n",
        "fig.add_vline(x=val_start, line_width=4, line_dash=\"dash\")\n",
        "fig.add_vline(x=test_start, line_width=4, line_dash=\"dash\")\n",
        "# fig.add_annotation(xref=\"paper\", x=0.75, yref=\"paper\", y=0.8, text=\"Test set start\", showarrow=False)\n",
        "fig.update_layout(\n",
        "  template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "afa1953de36fe74bf64e0007a050b01fd0993b8df6207b9778c7f34846b9bbf9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit ('complete3.8': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "057dd4f81caa4b10b86af42fc6898b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dc977552c4444ee871c590b208d7cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_057dd4f81caa4b10b86af42fc6898b6d",
            "placeholder": "​",
            "style": "IPY_MODEL_c0e4307aa3b343d9ac4077e0e0b8cd64",
            "value": " 100/100 [00:48&lt;00:00,  2.18it/s]"
          }
        },
        "12ba59388b344b009e9ff1a130672b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ccdf5616514a5091dadfc0ef31a59c",
            "placeholder": "​",
            "style": "IPY_MODEL_34f8d1cf490c441ab1c7e7446f14b64f",
            "value": "  3%"
          }
        },
        "19ae245c3a1e4269bcc74917dcf62285": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d780343266a94c1d906535353e39a910",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_246264fe31d34762b72938555f0d5800",
            "value": 3
          }
        },
        "246264fe31d34762b72938555f0d5800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d6f7f662e8a4e3bb073e958ffa97269": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34f8d1cf490c441ab1c7e7446f14b64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "367cef23640a4da9a1af04b9fbaa8a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcb723c3f917474c8af64be7c5f92517",
              "IPY_MODEL_e5c520643bff4e8d88107a9e09e2f832",
              "IPY_MODEL_0dc977552c4444ee871c590b208d7cfb"
            ],
            "layout": "IPY_MODEL_4df3be4f7911417497bd051d23b4c613"
          }
        },
        "4be36467cce24930839213fbc7af5d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df3be4f7911417497bd051d23b4c613": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6015fb50d0624ca8a4cc0c49e45a7732": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be36467cce24930839213fbc7af5d7b",
            "placeholder": "​",
            "style": "IPY_MODEL_aa39bb464ef644cc914b88644cad4aca",
            "value": " 3/100 [00:02&lt;00:51,  1.88it/s]"
          }
        },
        "68ccdf5616514a5091dadfc0ef31a59c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d0c69dd65c24fd4a5a5898e75d5d64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92463d63210c45dd9331767c8b3188f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12ba59388b344b009e9ff1a130672b40",
              "IPY_MODEL_19ae245c3a1e4269bcc74917dcf62285",
              "IPY_MODEL_6015fb50d0624ca8a4cc0c49e45a7732"
            ],
            "layout": "IPY_MODEL_ca40abd7b34e4197b522ce8b471be95b"
          }
        },
        "aa39bb464ef644cc914b88644cad4aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0e4307aa3b343d9ac4077e0e0b8cd64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0eefb3b3952463d8f4347c4639a06d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca40abd7b34e4197b522ce8b471be95b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d780343266a94c1d906535353e39a910": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb723c3f917474c8af64be7c5f92517": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_def03ac052304dfb8a4c34082fd4c0f6",
            "placeholder": "​",
            "style": "IPY_MODEL_6d0c69dd65c24fd4a5a5898e75d5d64a",
            "value": "100%"
          }
        },
        "def03ac052304dfb8a4c34082fd4c0f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c520643bff4e8d88107a9e09e2f832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0eefb3b3952463d8f4347c4639a06d9",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d6f7f662e8a4e3bb073e958ffa97269",
            "value": 100
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
